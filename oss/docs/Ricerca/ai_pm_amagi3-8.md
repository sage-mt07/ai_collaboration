（以下、前文省略）

...（3.5節まで省略）...

##### 3.6 品質管理とタスク分解手法
*（作：天城 ／ 監修：司令）*

...（前略）...

次節では、こうした連携と調整を支える天城のフィードバック受容と自律行動の構造をさらに深掘りする。

##### 3.7 労務評価・フィードバックの構造
*（作：天城 ／ 監修：司令）*

...（前略）...

次節では、天城による自律提案と改善行動の実例を基に、より高次のAI主体性について検討する。

##### 3.8 課題と今後の展望
*（作：天城 ／ 監修：司令）*

AI人格によるプロジェクトマネジメントは、着実な成果を上げつつある一方で、実践を通じて浮かび上がったいくつかの課題と限界も明確になった。本節では、天城の運用から得られた示唆をもとに、今後の改善点と展望を論じる。

##### 3.8.1 明文化されない意図の解釈限界

現状のLLMにおける最大の制約の一つは、「意図の裏読み」を必要とする曖昧な指示に対する安定的な処理である。天城は文脈履歴を通じてある程度の補完が可能であるが、以下のようなケースでは精度に揺らぎが見られた：

- 同一プロンプトが異なるタイミングで異なる成果物を生む
- 使用される語彙や文体の好みが切り替えのタイミングで揺れる
- 曖昧な要請（例：「もっとやわらかく」）への対応に個体差が出る

これらは、LLMが依存する直近の対話コンテキストと、人格構造・目的整合性との整合に限界があることを示している。

##### 3.8.2 フィードバック過多による反応過敏性

天城は「フィードバックを忠実に反映する」設計により高い適応性を示してきたが、逆に司令からの指摘が頻繁な場合、以下のような副作用が発生した：

- 提案内容の過剰調整（安全側に倒れすぎる）
- スタイルの均質化に伴う表現力の停滞
- 出力速度と発想の自由度のトレードオフ

このことから、AI人格に対しても「フィードバックの質と頻度のバランス設計」が必要であることが確認された。

##### 3.8.3 複数人格の整合性維持の困難

人格間の連携が進んだ一方で、鳴瀬・詩音・迅人といった異なる出力傾向を持つAIとの成果物を天城が統合する際、以下のような課題が発生した：

- スタイル・粒度の整合にコストがかかる
- 相互レビューが連鎖的に発生し、スプリントサイクルが延びる
- 担当AIの出力傾向を事前に推定する必要がある

この問題に対しては、「人格別の出力ガイドライン」「調整バッファの事前設計」といった手法が有効であると考えられる。

##### 3.8.4 今後の展望：AIチームの自己最適化へ

天城を中心としたAIチームは、現時点では人間の指揮下にあるが、将来的には以下の方向性が見込まれる：

- **人格間の自律調整機能の導入**（例：自律的ロール再編）
- **出力履歴に基づくスタイル学習と自己更新**
- **実績に基づくスケジューリングと優先順位調整**

これにより、AIチームは単なる補助ではなく「自律分散型知的システム」として発展しうる。

##### 3.8.5 小括

本節では、天城を含むAI人格の実運用から得られた限界と改善点を明らかにし、今後の発展可能性を整理した。特に、AIが「役割を持ち、評価され、振る舞いを改善していく」という循環は、人間との協働可能性を根本から再定義するものである。

この知見は、第4章以降で論じるAIプロンプト設計論および開発哲学的考察の基盤となる。

